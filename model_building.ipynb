{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in this notebook?\n",
    "Developing and testing models.\n",
    "- Models:\n",
    "    - Logistic regression\n",
    "    - KNN\n",
    "    - SVM\n",
    "    - Random Forest\n",
    "    - XGBoost\n",
    "    \n",
    "- Evaluation Metrics:\n",
    "    - ROC-AUC\n",
    "    - Accuracy score\n",
    "    - F1 score\n",
    "    \n",
    "- Other things to note:\n",
    "    - PCA used in conjunction with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "# I'll import sklearn models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>sec_duration_range</th>\n",
       "      <th>seg_duration_range</th>\n",
       "      <th>sec_loudness_range</th>\n",
       "      <th>sec_key_range</th>\n",
       "      <th>sec_tempo_range</th>\n",
       "      <th>sec_mode_range</th>\n",
       "      <th>sec_time_signature_range</th>\n",
       "      <th>no_unique_pitches</th>\n",
       "      <th>no_unique_timbres</th>\n",
       "      <th>mean_pitch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4cCio6f3kmmufjWVsEfMu0</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.294</td>\n",
       "      <td>16027</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597</td>\n",
       "      <td>-23.044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328</td>\n",
       "      <td>130</td>\n",
       "      <td>0.319427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6AyIvQ7Npap06gZzsHU3Hy</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.179</td>\n",
       "      <td>15427</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.916</td>\n",
       "      <td>7</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-21.892</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347</td>\n",
       "      <td>160</td>\n",
       "      <td>0.387112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acousticness  danceability  duration_ms  energy  \\\n",
       "id                                                                        \n",
       "4cCio6f3kmmufjWVsEfMu0         0.964         0.294        16027  0.0783   \n",
       "6AyIvQ7Npap06gZzsHU3Hy         0.927         0.179        15427  0.1410   \n",
       "\n",
       "                        instrumentalness  key  liveness  loudness  mode  \\\n",
       "id                                                                        \n",
       "4cCio6f3kmmufjWVsEfMu0             0.923    0     0.597   -23.044     1   \n",
       "6AyIvQ7Npap06gZzsHU3Hy             0.916    7     0.189   -21.892     0   \n",
       "\n",
       "                        speechiness  ...  sec_duration_range  \\\n",
       "id                                   ...                       \n",
       "4cCio6f3kmmufjWVsEfMu0       0.0400  ...                 NaN   \n",
       "6AyIvQ7Npap06gZzsHU3Hy       0.0555  ...                 NaN   \n",
       "\n",
       "                        seg_duration_range  sec_loudness_range  sec_key_range  \\\n",
       "id                                                                              \n",
       "4cCio6f3kmmufjWVsEfMu0                 NaN                 NaN            NaN   \n",
       "6AyIvQ7Npap06gZzsHU3Hy                 NaN                 NaN            NaN   \n",
       "\n",
       "                        sec_tempo_range  sec_mode_range  \\\n",
       "id                                                        \n",
       "4cCio6f3kmmufjWVsEfMu0              NaN             NaN   \n",
       "6AyIvQ7Npap06gZzsHU3Hy              NaN             NaN   \n",
       "\n",
       "                        sec_time_signature_range  no_unique_pitches  \\\n",
       "id                                                                    \n",
       "4cCio6f3kmmufjWVsEfMu0                       NaN                328   \n",
       "6AyIvQ7Npap06gZzsHU3Hy                       NaN                347   \n",
       "\n",
       "                        no_unique_timbres  mean_pitch  \n",
       "id                                                     \n",
       "4cCio6f3kmmufjWVsEfMu0                130    0.319427  \n",
       "6AyIvQ7Npap06gZzsHU3Hy                160    0.387112  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['4cCio6f3kmmufjWVsEfMu0', '6AyIvQ7Npap06gZzsHU3Hy'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('ballet', axis=1)\n",
    "y = data['ballet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_unique_timbres</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>sec_time_signature_range</th>\n",
       "      <th>seg_duration_range</th>\n",
       "      <th>...</th>\n",
       "      <th>sec_key_range</th>\n",
       "      <th>liveness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>sec_mode_range</th>\n",
       "      <th>sec_duration_range</th>\n",
       "      <th>no_unique_pitches</th>\n",
       "      <th>no_segments</th>\n",
       "      <th>mean_pitch</th>\n",
       "      <th>mode</th>\n",
       "      <th>no_sections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.381652</td>\n",
       "      <td>-0.868784</td>\n",
       "      <td>-0.647385</td>\n",
       "      <td>-1.020334</td>\n",
       "      <td>0.961208</td>\n",
       "      <td>-0.597610</td>\n",
       "      <td>-0.345203</td>\n",
       "      <td>-3.066970</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.399516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.114207</td>\n",
       "      <td>-0.751827</td>\n",
       "      <td>-0.206105</td>\n",
       "      <td>-0.293466</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>-0.311422</td>\n",
       "      <td>-0.049848</td>\n",
       "      <td>-0.230527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.916531</td>\n",
       "      <td>-0.868784</td>\n",
       "      <td>-0.816355</td>\n",
       "      <td>-0.581445</td>\n",
       "      <td>0.636082</td>\n",
       "      <td>-1.174172</td>\n",
       "      <td>-0.418860</td>\n",
       "      <td>-2.066163</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616202</td>\n",
       "      <td>-0.616202</td>\n",
       "      <td>-0.902028</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.550939</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>-0.477337</td>\n",
       "      <td>-1.275272</td>\n",
       "      <td>-0.303023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566415</td>\n",
       "      <td>-1.271590</td>\n",
       "      <td>-0.650258</td>\n",
       "      <td>-0.380097</td>\n",
       "      <td>0.569852</td>\n",
       "      <td>1.708639</td>\n",
       "      <td>3.735404</td>\n",
       "      <td>-0.018884</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.360216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614479</td>\n",
       "      <td>-0.614479</td>\n",
       "      <td>0.348017</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.621966</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.131017</td>\n",
       "      <td>-0.301217</td>\n",
       "      <td>0.188947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.391376</td>\n",
       "      <td>0.828753</td>\n",
       "      <td>-0.828020</td>\n",
       "      <td>1.725991</td>\n",
       "      <td>-1.462189</td>\n",
       "      <td>0.843796</td>\n",
       "      <td>4.663484</td>\n",
       "      <td>0.347440</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.175506</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.294138</td>\n",
       "      <td>-1.294138</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>-0.641776</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>-0.138594</td>\n",
       "      <td>-0.254085</td>\n",
       "      <td>0.222484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.673384</td>\n",
       "      <td>0.713665</td>\n",
       "      <td>-0.918203</td>\n",
       "      <td>1.793956</td>\n",
       "      <td>0.726394</td>\n",
       "      <td>1.132077</td>\n",
       "      <td>-0.433591</td>\n",
       "      <td>-0.151547</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.614424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860099</td>\n",
       "      <td>-0.860099</td>\n",
       "      <td>-0.646890</td>\n",
       "      <td>-1.343613</td>\n",
       "      <td>-0.608379</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>-0.581033</td>\n",
       "      <td>-0.615428</td>\n",
       "      <td>-0.555043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.371927</td>\n",
       "      <td>-1.134924</td>\n",
       "      <td>-0.072567</td>\n",
       "      <td>-0.671500</td>\n",
       "      <td>0.774561</td>\n",
       "      <td>1.132077</td>\n",
       "      <td>0.796483</td>\n",
       "      <td>-0.731865</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.301266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300452</td>\n",
       "      <td>-0.300452</td>\n",
       "      <td>-0.499783</td>\n",
       "      <td>-0.206105</td>\n",
       "      <td>-0.515867</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>0.587282</td>\n",
       "      <td>0.484312</td>\n",
       "      <td>0.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.595588</td>\n",
       "      <td>-1.142117</td>\n",
       "      <td>-0.640317</td>\n",
       "      <td>-0.900884</td>\n",
       "      <td>-1.170177</td>\n",
       "      <td>1.132077</td>\n",
       "      <td>1.555152</td>\n",
       "      <td>-1.407847</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.048504</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.064762</td>\n",
       "      <td>-1.064762</td>\n",
       "      <td>-0.968621</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.635773</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>-1.085690</td>\n",
       "      <td>0.500022</td>\n",
       "      <td>-1.069639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.498344</td>\n",
       "      <td>0.116650</td>\n",
       "      <td>-0.646282</td>\n",
       "      <td>0.715001</td>\n",
       "      <td>0.503623</td>\n",
       "      <td>-0.885891</td>\n",
       "      <td>0.752289</td>\n",
       "      <td>-0.325042</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.037956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.798268</td>\n",
       "      <td>-0.798268</td>\n",
       "      <td>-0.822735</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.567937</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>0.310758</td>\n",
       "      <td>-0.364059</td>\n",
       "      <td>0.349508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.780352</td>\n",
       "      <td>-0.127910</td>\n",
       "      <td>-0.913520</td>\n",
       "      <td>-1.040214</td>\n",
       "      <td>-0.122547</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>0.258786</td>\n",
       "      <td>-2.457153</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.318813</td>\n",
       "      <td>-1.318813</td>\n",
       "      <td>-1.190055</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.793056</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>-3.083578</td>\n",
       "      <td>-0.772534</td>\n",
       "      <td>-3.736436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.391376</td>\n",
       "      <td>-1.490256</td>\n",
       "      <td>-0.324250</td>\n",
       "      <td>-0.888140</td>\n",
       "      <td>0.792624</td>\n",
       "      <td>1.708639</td>\n",
       "      <td>-0.455688</td>\n",
       "      <td>-1.476179</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.085116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187176</td>\n",
       "      <td>0.187176</td>\n",
       "      <td>-0.600975</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>1.006568</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>0.213974</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.239879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.566415</td>\n",
       "      <td>-0.322120</td>\n",
       "      <td>-0.800888</td>\n",
       "      <td>-0.354610</td>\n",
       "      <td>0.326007</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>1.437301</td>\n",
       "      <td>-0.235045</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.254106</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.115170</td>\n",
       "      <td>-1.115170</td>\n",
       "      <td>-0.707540</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.684399</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>-0.601773</td>\n",
       "      <td>-0.552586</td>\n",
       "      <td>-0.562545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.070471</td>\n",
       "      <td>0.605771</td>\n",
       "      <td>-0.833674</td>\n",
       "      <td>4.036824</td>\n",
       "      <td>0.536737</td>\n",
       "      <td>0.555515</td>\n",
       "      <td>0.936432</td>\n",
       "      <td>1.667405</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.258036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.772753</td>\n",
       "      <td>-0.772753</td>\n",
       "      <td>-0.950873</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.758016</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>-0.339074</td>\n",
       "      <td>-0.992481</td>\n",
       "      <td>0.021379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.289332</td>\n",
       "      <td>-0.926328</td>\n",
       "      <td>-0.886034</td>\n",
       "      <td>-0.708881</td>\n",
       "      <td>0.720374</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>3.610187</td>\n",
       "      <td>-0.361875</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.470256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523113</td>\n",
       "      <td>-0.523113</td>\n",
       "      <td>-0.409255</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.788317</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>-1.217039</td>\n",
       "      <td>-1.479509</td>\n",
       "      <td>-1.024897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.352478</td>\n",
       "      <td>-0.171068</td>\n",
       "      <td>-0.908791</td>\n",
       "      <td>0.043839</td>\n",
       "      <td>0.804666</td>\n",
       "      <td>-0.021047</td>\n",
       "      <td>3.448141</td>\n",
       "      <td>1.045755</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.649794</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.150751</td>\n",
       "      <td>-1.150751</td>\n",
       "      <td>-0.234469</td>\n",
       "      <td>-1.722782</td>\n",
       "      <td>-0.653403</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>-0.850644</td>\n",
       "      <td>-0.929639</td>\n",
       "      <td>-0.727588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.109369</td>\n",
       "      <td>0.267702</td>\n",
       "      <td>-0.916258</td>\n",
       "      <td>0.145788</td>\n",
       "      <td>-1.685864</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>4.302564</td>\n",
       "      <td>0.391939</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.370764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667729</td>\n",
       "      <td>-0.667729</td>\n",
       "      <td>-1.188264</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>0.307293</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>-0.947428</td>\n",
       "      <td>-0.961060</td>\n",
       "      <td>-0.894225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.410825</td>\n",
       "      <td>0.598578</td>\n",
       "      <td>-1.000565</td>\n",
       "      <td>1.547581</td>\n",
       "      <td>0.675217</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>2.254895</td>\n",
       "      <td>-0.032883</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.094205</td>\n",
       "      <td>-1.094205</td>\n",
       "      <td>-1.561364</td>\n",
       "      <td>-1.343613</td>\n",
       "      <td>-0.745789</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>-1.929089</td>\n",
       "      <td>-0.961060</td>\n",
       "      <td>-1.647087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.333030</td>\n",
       "      <td>0.972612</td>\n",
       "      <td>-0.954789</td>\n",
       "      <td>1.309701</td>\n",
       "      <td>0.876916</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>4.751873</td>\n",
       "      <td>0.768762</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.434449</td>\n",
       "      <td>-1.434449</td>\n",
       "      <td>-0.304400</td>\n",
       "      <td>-0.964443</td>\n",
       "      <td>-0.754225</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>-0.663991</td>\n",
       "      <td>-0.929639</td>\n",
       "      <td>-0.346604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.070471</td>\n",
       "      <td>0.246123</td>\n",
       "      <td>-0.188732</td>\n",
       "      <td>2.957869</td>\n",
       "      <td>0.648123</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>-0.256814</td>\n",
       "      <td>1.228083</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.288234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>1.067677</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.476878</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>0.843067</td>\n",
       "      <td>0.939918</td>\n",
       "      <td>0.857479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.245510</td>\n",
       "      <td>-0.919135</td>\n",
       "      <td>-0.611637</td>\n",
       "      <td>-0.964602</td>\n",
       "      <td>0.801655</td>\n",
       "      <td>-1.174172</td>\n",
       "      <td>-0.455688</td>\n",
       "      <td>-1.390514</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.159786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256018</td>\n",
       "      <td>-0.256018</td>\n",
       "      <td>0.172335</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>0.464355</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>-0.504989</td>\n",
       "      <td>-0.364059</td>\n",
       "      <td>-0.413555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.585864</td>\n",
       "      <td>-0.278962</td>\n",
       "      <td>-0.897524</td>\n",
       "      <td>-0.436168</td>\n",
       "      <td>-0.833009</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>2.652644</td>\n",
       "      <td>0.650432</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.053676</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.202934</td>\n",
       "      <td>-1.202934</td>\n",
       "      <td>-0.177238</td>\n",
       "      <td>-0.964443</td>\n",
       "      <td>-0.625599</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>-1.210126</td>\n",
       "      <td>-0.772534</td>\n",
       "      <td>-0.860591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-6.046174</td>\n",
       "      <td>-0.645803</td>\n",
       "      <td>-0.852189</td>\n",
       "      <td>-0.920424</td>\n",
       "      <td>1.024427</td>\n",
       "      <td>1.708639</td>\n",
       "      <td>2.063386</td>\n",
       "      <td>-2.983972</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.489906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.945738</td>\n",
       "      <td>-0.945738</td>\n",
       "      <td>0.911941</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.713593</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>-0.615599</td>\n",
       "      <td>-1.463798</td>\n",
       "      <td>0.038030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.167715</td>\n",
       "      <td>-0.739311</td>\n",
       "      <td>-0.567628</td>\n",
       "      <td>0.392164</td>\n",
       "      <td>0.894979</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>-0.851964</td>\n",
       "      <td>1.563908</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.588156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.863883</td>\n",
       "      <td>-0.863883</td>\n",
       "      <td>0.966729</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.432013</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>-0.131681</td>\n",
       "      <td>-0.474033</td>\n",
       "      <td>-0.203547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.615037</td>\n",
       "      <td>2.145063</td>\n",
       "      <td>-0.322175</td>\n",
       "      <td>1.658025</td>\n",
       "      <td>0.813697</td>\n",
       "      <td>0.555515</td>\n",
       "      <td>0.096740</td>\n",
       "      <td>1.201917</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.128346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103978</td>\n",
       "      <td>-0.103978</td>\n",
       "      <td>-0.056019</td>\n",
       "      <td>-0.206105</td>\n",
       "      <td>-0.705378</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.732457</td>\n",
       "      <td>-0.049848</td>\n",
       "      <td>0.809527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.702557</td>\n",
       "      <td>-0.228612</td>\n",
       "      <td>1.203623</td>\n",
       "      <td>0.324198</td>\n",
       "      <td>0.660165</td>\n",
       "      <td>1.132077</td>\n",
       "      <td>1.636175</td>\n",
       "      <td>0.117613</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.238386</td>\n",
       "      <td>...</td>\n",
       "      <td>1.042614</td>\n",
       "      <td>1.042614</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>0.756931</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>1.008982</td>\n",
       "      <td>1.442656</td>\n",
       "      <td>1.020704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.576140</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.387437</td>\n",
       "      <td>1.590059</td>\n",
       "      <td>0.461477</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>-0.470420</td>\n",
       "      <td>0.686098</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.614424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756540</td>\n",
       "      <td>-0.756540</td>\n",
       "      <td>0.460036</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.548790</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>0.677152</td>\n",
       "      <td>0.358627</td>\n",
       "      <td>0.632663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.615037</td>\n",
       "      <td>0.267702</td>\n",
       "      <td>-0.947409</td>\n",
       "      <td>2.422639</td>\n",
       "      <td>-0.251996</td>\n",
       "      <td>-0.885891</td>\n",
       "      <td>0.074643</td>\n",
       "      <td>1.377746</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>3.271104</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.276494</td>\n",
       "      <td>-1.276494</td>\n",
       "      <td>-1.036679</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.742566</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>-0.601773</td>\n",
       "      <td>-1.432377</td>\n",
       "      <td>-0.311881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.109369</td>\n",
       "      <td>0.864717</td>\n",
       "      <td>-0.260622</td>\n",
       "      <td>1.658025</td>\n",
       "      <td>0.353101</td>\n",
       "      <td>-0.885891</td>\n",
       "      <td>0.840678</td>\n",
       "      <td>1.747569</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.417924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008681</td>\n",
       "      <td>-0.008681</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>0.722491</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>0.808501</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>0.815018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.196888</td>\n",
       "      <td>-0.631417</td>\n",
       "      <td>-0.755775</td>\n",
       "      <td>-0.904282</td>\n",
       "      <td>-1.836687</td>\n",
       "      <td>-0.597610</td>\n",
       "      <td>0.730192</td>\n",
       "      <td>-2.065496</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.131034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353466</td>\n",
       "      <td>-0.353466</td>\n",
       "      <td>-0.829899</td>\n",
       "      <td>-1.722782</td>\n",
       "      <td>-0.578585</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>-1.258518</td>\n",
       "      <td>1.332682</td>\n",
       "      <td>-1.319917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.187164</td>\n",
       "      <td>1.195593</td>\n",
       "      <td>-0.583270</td>\n",
       "      <td>1.912896</td>\n",
       "      <td>-0.023203</td>\n",
       "      <td>1.132077</td>\n",
       "      <td>2.159141</td>\n",
       "      <td>1.225417</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.226596</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.087017</td>\n",
       "      <td>-1.087017</td>\n",
       "      <td>-0.250507</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>-0.444904</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.587282</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.613579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.478896</td>\n",
       "      <td>-0.070367</td>\n",
       "      <td>-0.314000</td>\n",
       "      <td>-0.075101</td>\n",
       "      <td>0.217632</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>1.231061</td>\n",
       "      <td>0.716263</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389206</td>\n",
       "      <td>-0.389206</td>\n",
       "      <td>0.683261</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.586326</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.552716</td>\n",
       "      <td>0.955629</td>\n",
       "      <td>0.479976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>0.819249</td>\n",
       "      <td>1.864538</td>\n",
       "      <td>0.649925</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>0.678228</td>\n",
       "      <td>-0.021047</td>\n",
       "      <td>-0.168425</td>\n",
       "      <td>-0.064216</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.032784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299288</td>\n",
       "      <td>0.299288</td>\n",
       "      <td>-0.877768</td>\n",
       "      <td>-1.343613</td>\n",
       "      <td>-0.598711</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>0.863806</td>\n",
       "      <td>3.265082</td>\n",
       "      <td>0.814212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>0.799801</td>\n",
       "      <td>-0.192647</td>\n",
       "      <td>0.425811</td>\n",
       "      <td>-0.785342</td>\n",
       "      <td>-1.808087</td>\n",
       "      <td>-0.597610</td>\n",
       "      <td>-0.411494</td>\n",
       "      <td>-0.504871</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.111384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312622</td>\n",
       "      <td>0.312622</td>\n",
       "      <td>-0.259787</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.500038</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>0.573456</td>\n",
       "      <td>1.505498</td>\n",
       "      <td>0.610308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>0.624762</td>\n",
       "      <td>-0.926328</td>\n",
       "      <td>0.641441</td>\n",
       "      <td>-0.268803</td>\n",
       "      <td>-0.525945</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>-0.057940</td>\n",
       "      <td>0.121946</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.482046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247543</td>\n",
       "      <td>0.247543</td>\n",
       "      <td>-0.226979</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.547210</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>1.002069</td>\n",
       "      <td>0.390048</td>\n",
       "      <td>0.976658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>0.566415</td>\n",
       "      <td>-1.362940</td>\n",
       "      <td>0.196925</td>\n",
       "      <td>-0.269652</td>\n",
       "      <td>0.684248</td>\n",
       "      <td>0.267234</td>\n",
       "      <td>1.312083</td>\n",
       "      <td>-0.428373</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.370764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303337</td>\n",
       "      <td>-0.303337</td>\n",
       "      <td>0.114127</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>1.815100</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.725544</td>\n",
       "      <td>0.154390</td>\n",
       "      <td>0.650864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>0.741454</td>\n",
       "      <td>0.210159</td>\n",
       "      <td>0.456035</td>\n",
       "      <td>-0.331671</td>\n",
       "      <td>-1.091906</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>-0.593427</td>\n",
       "      <td>0.066447</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.285546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735474</td>\n",
       "      <td>0.735474</td>\n",
       "      <td>-0.462334</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.514604</td>\n",
       "      <td>-2.141691</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>0.822328</td>\n",
       "      <td>1.285550</td>\n",
       "      <td>0.813649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>0.722005</td>\n",
       "      <td>1.605592</td>\n",
       "      <td>0.383392</td>\n",
       "      <td>-0.390292</td>\n",
       "      <td>0.952177</td>\n",
       "      <td>-0.885891</td>\n",
       "      <td>-0.731166</td>\n",
       "      <td>-0.014717</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.881664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495925</td>\n",
       "      <td>0.495925</td>\n",
       "      <td>-0.667812</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>-0.355930</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.677152</td>\n",
       "      <td>2.479553</td>\n",
       "      <td>0.615333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0.517793</td>\n",
       "      <td>0.231737</td>\n",
       "      <td>0.849294</td>\n",
       "      <td>0.927394</td>\n",
       "      <td>0.241715</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>-0.315740</td>\n",
       "      <td>2.049728</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.340566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.701146</td>\n",
       "      <td>-0.701146</td>\n",
       "      <td>-1.102051</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.329264</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.898372</td>\n",
       "      <td>1.772578</td>\n",
       "      <td>0.865535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0.576140</td>\n",
       "      <td>1.152436</td>\n",
       "      <td>-0.455662</td>\n",
       "      <td>-0.126075</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>-0.885891</td>\n",
       "      <td>-0.043208</td>\n",
       "      <td>0.634932</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.065466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779343</td>\n",
       "      <td>-0.779343</td>\n",
       "      <td>-0.845204</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.410054</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>-0.276856</td>\n",
       "      <td>-0.238374</td>\n",
       "      <td>-0.426454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0.692832</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>2.821812</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>0.825739</td>\n",
       "      <td>-0.597610</td>\n",
       "      <td>-0.647197</td>\n",
       "      <td>0.707597</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.356286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618933</td>\n",
       "      <td>0.618933</td>\n",
       "      <td>0.264897</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.186167</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>1.015895</td>\n",
       "      <td>1.913973</td>\n",
       "      <td>1.030863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>0.819249</td>\n",
       "      <td>1.260330</td>\n",
       "      <td>-0.601477</td>\n",
       "      <td>2.116793</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>0.244055</td>\n",
       "      <td>1.205750</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.348426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373298</td>\n",
       "      <td>-0.373298</td>\n",
       "      <td>-1.345059</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>-0.739470</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>-0.290683</td>\n",
       "      <td>0.138679</td>\n",
       "      <td>-0.241711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>-1.563228</td>\n",
       "      <td>-0.156682</td>\n",
       "      <td>-0.097090</td>\n",
       "      <td>0.307206</td>\n",
       "      <td>-1.886629</td>\n",
       "      <td>-1.174172</td>\n",
       "      <td>-0.396763</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.151926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.555406</td>\n",
       "      <td>-0.555406</td>\n",
       "      <td>1.802480</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.500228</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>0.317671</td>\n",
       "      <td>-0.316927</td>\n",
       "      <td>0.285957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.517793</td>\n",
       "      <td>0.425947</td>\n",
       "      <td>0.582761</td>\n",
       "      <td>0.349685</td>\n",
       "      <td>0.816707</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>-0.795984</td>\n",
       "      <td>0.596767</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.344496</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006400</td>\n",
       "      <td>1.006400</td>\n",
       "      <td>0.246987</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.159500</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>0.953677</td>\n",
       "      <td>0.484312</td>\n",
       "      <td>0.955101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.819249</td>\n",
       "      <td>1.339452</td>\n",
       "      <td>-0.459152</td>\n",
       "      <td>0.069327</td>\n",
       "      <td>0.888958</td>\n",
       "      <td>-0.021047</td>\n",
       "      <td>-0.718644</td>\n",
       "      <td>-0.373374</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.103524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219846</td>\n",
       "      <td>-0.219846</td>\n",
       "      <td>-1.181262</td>\n",
       "      <td>-0.206105</td>\n",
       "      <td>-0.707748</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>-0.511902</td>\n",
       "      <td>0.861365</td>\n",
       "      <td>-0.346240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.683108</td>\n",
       "      <td>0.807174</td>\n",
       "      <td>1.498742</td>\n",
       "      <td>0.698009</td>\n",
       "      <td>0.837780</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>-0.635412</td>\n",
       "      <td>0.672598</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.395586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473708</td>\n",
       "      <td>0.473708</td>\n",
       "      <td>-0.392322</td>\n",
       "      <td>-0.206105</td>\n",
       "      <td>-0.265567</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>0.995155</td>\n",
       "      <td>1.536919</td>\n",
       "      <td>0.985057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0.556691</td>\n",
       "      <td>0.260509</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>0.290215</td>\n",
       "      <td>-1.284574</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>-0.389397</td>\n",
       "      <td>1.209584</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.061536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165159</td>\n",
       "      <td>-0.165159</td>\n",
       "      <td>-1.053449</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.632834</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.462846</td>\n",
       "      <td>0.924207</td>\n",
       "      <td>0.404680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>0.741454</td>\n",
       "      <td>0.253316</td>\n",
       "      <td>-0.422874</td>\n",
       "      <td>-0.522825</td>\n",
       "      <td>-1.886653</td>\n",
       "      <td>-0.885891</td>\n",
       "      <td>-0.630992</td>\n",
       "      <td>-0.130048</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.116556</td>\n",
       "      <td>...</td>\n",
       "      <td>1.221345</td>\n",
       "      <td>1.221345</td>\n",
       "      <td>-0.167062</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>-0.169832</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.359149</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.276800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.181387</td>\n",
       "      <td>1.066160</td>\n",
       "      <td>-0.202536</td>\n",
       "      <td>0.801655</td>\n",
       "      <td>0.843796</td>\n",
       "      <td>-0.374665</td>\n",
       "      <td>-0.074882</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.395586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201369</td>\n",
       "      <td>0.201369</td>\n",
       "      <td>-0.427573</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.279564</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.919111</td>\n",
       "      <td>2.008236</td>\n",
       "      <td>0.914912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>0.206612</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>-0.875476</td>\n",
       "      <td>-0.007135</td>\n",
       "      <td>-1.886642</td>\n",
       "      <td>0.555515</td>\n",
       "      <td>1.245792</td>\n",
       "      <td>1.112086</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.296094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287199</td>\n",
       "      <td>-0.287199</td>\n",
       "      <td>-1.454310</td>\n",
       "      <td>-2.101951</td>\n",
       "      <td>-0.605852</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>-1.223952</td>\n",
       "      <td>-0.254085</td>\n",
       "      <td>-1.289781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.627350</td>\n",
       "      <td>0.490543</td>\n",
       "      <td>-0.168553</td>\n",
       "      <td>0.684248</td>\n",
       "      <td>1.420358</td>\n",
       "      <td>0.700729</td>\n",
       "      <td>0.068114</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.030096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289753</td>\n",
       "      <td>-0.289753</td>\n",
       "      <td>-0.518100</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.424840</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>0.801588</td>\n",
       "      <td>0.625707</td>\n",
       "      <td>0.753081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>0.712281</td>\n",
       "      <td>0.598578</td>\n",
       "      <td>0.595397</td>\n",
       "      <td>-0.269652</td>\n",
       "      <td>0.861864</td>\n",
       "      <td>0.267234</td>\n",
       "      <td>-0.569120</td>\n",
       "      <td>-0.558370</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.191226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.748963</td>\n",
       "      <td>-0.748963</td>\n",
       "      <td>-0.713483</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.204840</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>0.870719</td>\n",
       "      <td>1.364103</td>\n",
       "      <td>0.901741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>0.663659</td>\n",
       "      <td>-0.768083</td>\n",
       "      <td>-0.453495</td>\n",
       "      <td>-1.000793</td>\n",
       "      <td>0.431372</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>-0.256814</td>\n",
       "      <td>-1.756504</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.293406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518550</td>\n",
       "      <td>-0.518550</td>\n",
       "      <td>-0.256938</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>-0.422123</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>-0.304509</td>\n",
       "      <td>-0.065558</td>\n",
       "      <td>-0.371060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>0.741454</td>\n",
       "      <td>-0.063174</td>\n",
       "      <td>-0.030016</td>\n",
       "      <td>-0.709730</td>\n",
       "      <td>-1.886482</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>-0.606686</td>\n",
       "      <td>-0.076382</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.508314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438147</td>\n",
       "      <td>0.438147</td>\n",
       "      <td>1.703486</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.666168</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>0.511238</td>\n",
       "      <td>0.484312</td>\n",
       "      <td>0.516311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>0.809525</td>\n",
       "      <td>0.749630</td>\n",
       "      <td>-0.745611</td>\n",
       "      <td>1.054829</td>\n",
       "      <td>0.925083</td>\n",
       "      <td>-1.174172</td>\n",
       "      <td>-0.448323</td>\n",
       "      <td>0.169778</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>-0.395586</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053474</td>\n",
       "      <td>-1.053474</td>\n",
       "      <td>-1.084385</td>\n",
       "      <td>-0.206105</td>\n",
       "      <td>1.970898</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>-1.521216</td>\n",
       "      <td>0.185811</td>\n",
       "      <td>-1.484993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>0.546966</td>\n",
       "      <td>-0.681768</td>\n",
       "      <td>-0.492600</td>\n",
       "      <td>-0.309582</td>\n",
       "      <td>0.657155</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>-0.681079</td>\n",
       "      <td>-0.652367</td>\n",
       "      <td>-1.512077</td>\n",
       "      <td>0.099594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289696</td>\n",
       "      <td>-0.289696</td>\n",
       "      <td>0.182511</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.730812</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>-0.186986</td>\n",
       "      <td>-0.536875</td>\n",
       "      <td>-0.372050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>0.790076</td>\n",
       "      <td>0.174194</td>\n",
       "      <td>0.575427</td>\n",
       "      <td>-0.356309</td>\n",
       "      <td>0.756499</td>\n",
       "      <td>-0.885891</td>\n",
       "      <td>-0.183157</td>\n",
       "      <td>-0.534203</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.072084</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024898</td>\n",
       "      <td>1.024898</td>\n",
       "      <td>-0.222583</td>\n",
       "      <td>-0.585274</td>\n",
       "      <td>1.418290</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>0.635674</td>\n",
       "      <td>1.175576</td>\n",
       "      <td>0.579253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0.157991</td>\n",
       "      <td>-0.480365</td>\n",
       "      <td>1.535991</td>\n",
       "      <td>0.060831</td>\n",
       "      <td>0.410299</td>\n",
       "      <td>1.132077</td>\n",
       "      <td>-0.396763</td>\n",
       "      <td>0.444604</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.293406</td>\n",
       "      <td>...</td>\n",
       "      <td>1.797904</td>\n",
       "      <td>1.797904</td>\n",
       "      <td>-0.151594</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>1.562777</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>1.029721</td>\n",
       "      <td>1.144155</td>\n",
       "      <td>1.009913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>0.751179</td>\n",
       "      <td>0.886296</td>\n",
       "      <td>-0.527154</td>\n",
       "      <td>-0.730970</td>\n",
       "      <td>-1.886660</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>-0.433591</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.555474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619263</td>\n",
       "      <td>0.619263</td>\n",
       "      <td>-0.830713</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>-0.604841</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-0.695168</td>\n",
       "      <td>0.220887</td>\n",
       "      <td>0.719970</td>\n",
       "      <td>0.260385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>0.780352</td>\n",
       "      <td>1.174014</td>\n",
       "      <td>0.762289</td>\n",
       "      <td>-0.510081</td>\n",
       "      <td>0.714353</td>\n",
       "      <td>1.132077</td>\n",
       "      <td>-0.532292</td>\n",
       "      <td>-0.329876</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>0.127104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247589</td>\n",
       "      <td>-0.247589</td>\n",
       "      <td>-0.699643</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>-0.518079</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>1.274372</td>\n",
       "      <td>0.780849</td>\n",
       "      <td>0.704260</td>\n",
       "      <td>0.792368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.770627</td>\n",
       "      <td>1.008576</td>\n",
       "      <td>0.380433</td>\n",
       "      <td>-0.202536</td>\n",
       "      <td>0.654144</td>\n",
       "      <td>-1.462453</td>\n",
       "      <td>0.273518</td>\n",
       "      <td>0.169945</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.324846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935717</td>\n",
       "      <td>0.935717</td>\n",
       "      <td>1.595049</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>-0.542566</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>0.704805</td>\n",
       "      <td>1.081313</td>\n",
       "      <td>0.646645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.556691</td>\n",
       "      <td>0.936647</td>\n",
       "      <td>0.572378</td>\n",
       "      <td>-0.100588</td>\n",
       "      <td>0.807676</td>\n",
       "      <td>-0.309329</td>\n",
       "      <td>1.407838</td>\n",
       "      <td>0.292441</td>\n",
       "      <td>0.661342</td>\n",
       "      <td>-0.226596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694435</td>\n",
       "      <td>0.694435</td>\n",
       "      <td>1.655048</td>\n",
       "      <td>0.552233</td>\n",
       "      <td>-0.620891</td>\n",
       "      <td>0.466921</td>\n",
       "      <td>-1.351682</td>\n",
       "      <td>0.836154</td>\n",
       "      <td>0.798523</td>\n",
       "      <td>0.852893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2123 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      no_unique_timbres     tempo   valence  danceability  instrumentalness  \\\n",
       "0              0.381652 -0.868784 -0.647385     -1.020334          0.961208   \n",
       "1             -3.916531 -0.868784 -0.816355     -0.581445          0.636082   \n",
       "2              0.566415 -1.271590 -0.650258     -0.380097          0.569852   \n",
       "3              0.391376  0.828753 -0.828020      1.725991         -1.462189   \n",
       "4              0.673384  0.713665 -0.918203      1.793956          0.726394   \n",
       "5              0.371927 -1.134924 -0.072567     -0.671500          0.774561   \n",
       "6              0.595588 -1.142117 -0.640317     -0.900884         -1.170177   \n",
       "7              0.498344  0.116650 -0.646282      0.715001          0.503623   \n",
       "8              0.780352 -0.127910 -0.913520     -1.040214         -0.122547   \n",
       "9              0.391376 -1.490256 -0.324250     -0.888140          0.792624   \n",
       "10             0.566415 -0.322120 -0.800888     -0.354610          0.326007   \n",
       "11             0.070471  0.605771 -0.833674      4.036824          0.536737   \n",
       "12            -0.289332 -0.926328 -0.886034     -0.708881          0.720374   \n",
       "13             0.352478 -0.171068 -0.908791      0.043839          0.804666   \n",
       "14             0.109369  0.267702 -0.916258      0.145788         -1.685864   \n",
       "15             0.410825  0.598578 -1.000565      1.547581          0.675217   \n",
       "16             0.333030  0.972612 -0.954789      1.309701          0.876916   \n",
       "17             0.070471  0.246123 -0.188732      2.957869          0.648123   \n",
       "18             0.245510 -0.919135 -0.611637     -0.964602          0.801655   \n",
       "19             0.585864 -0.278962 -0.897524     -0.436168         -0.833009   \n",
       "20            -6.046174 -0.645803 -0.852189     -0.920424          1.024427   \n",
       "21             0.167715 -0.739311 -0.567628      0.392164          0.894979   \n",
       "22             0.615037  2.145063 -0.322175      1.658025          0.813697   \n",
       "23             0.702557 -0.228612  1.203623      0.324198          0.660165   \n",
       "24             0.576140  0.087878 -0.387437      1.590059          0.461477   \n",
       "25             0.615037  0.267702 -0.947409      2.422639         -0.251996   \n",
       "26             0.109369  0.864717 -0.260622      1.658025          0.353101   \n",
       "27             0.196888 -0.631417 -0.755775     -0.904282         -1.836687   \n",
       "28             0.187164  1.195593 -0.583270      1.912896         -0.023203   \n",
       "29             0.478896 -0.070367 -0.314000     -0.075101          0.217632   \n",
       "...                 ...       ...       ...           ...               ...   \n",
       "2093           0.819249  1.864538  0.649925     -0.553409          0.678228   \n",
       "2094           0.799801 -0.192647  0.425811     -0.785342         -1.808087   \n",
       "2095           0.624762 -0.926328  0.641441     -0.268803         -0.525945   \n",
       "2096           0.566415 -1.362940  0.196925     -0.269652          0.684248   \n",
       "2097           0.741454  0.210159  0.456035     -0.331671         -1.091906   \n",
       "2098           0.722005  1.605592  0.383392     -0.390292          0.952177   \n",
       "2099           0.517793  0.231737  0.849294      0.927394          0.241715   \n",
       "2100           0.576140  1.152436 -0.455662     -0.126075          0.753488   \n",
       "2101           0.692832  0.591385  2.821812      0.018352          0.825739   \n",
       "2102           0.819249  1.260330 -0.601477      2.116793          0.753488   \n",
       "2103          -1.563228 -0.156682 -0.097090      0.307206         -1.886629   \n",
       "2104           0.517793  0.425947  0.582761      0.349685          0.816707   \n",
       "2105           0.819249  1.339452 -0.459152      0.069327          0.888958   \n",
       "2106           0.683108  0.807174  1.498742      0.698009          0.837780   \n",
       "2107           0.556691  0.260509 -0.090728      0.290215         -1.284574   \n",
       "2108           0.741454  0.253316 -0.422874     -0.522825         -1.886653   \n",
       "2109           0.799801  0.181387  1.066160     -0.202536          0.801655   \n",
       "2110           0.206612  0.037528 -0.875476     -0.007135         -1.886642   \n",
       "2111           0.799801  0.627350  0.490543     -0.168553          0.684248   \n",
       "2112           0.712281  0.598578  0.595397     -0.269652          0.861864   \n",
       "2113           0.663659 -0.768083 -0.453495     -1.000793          0.431372   \n",
       "2114           0.741454 -0.063174 -0.030016     -0.709730         -1.886482   \n",
       "2115           0.809525  0.749630 -0.745611      1.054829          0.925083   \n",
       "2116           0.546966 -0.681768 -0.492600     -0.309582          0.657155   \n",
       "2117           0.790076  0.174194  0.575427     -0.356309          0.756499   \n",
       "2118           0.157991 -0.480365  1.535991      0.060831          0.410299   \n",
       "2119           0.751179  0.886296 -0.527154     -0.730970         -1.886660   \n",
       "2120           0.780352  1.174014  0.762289     -0.510081          0.714353   \n",
       "2121           0.770627  1.008576  0.380433     -0.202536          0.654144   \n",
       "2122           0.556691  0.936647  0.572378     -0.100588          0.807676   \n",
       "\n",
       "      duration_ms  acousticness  speechiness  sec_time_signature_range  \\\n",
       "0       -0.597610     -0.345203    -3.066970                  0.661342   \n",
       "1       -1.174172     -0.418860    -2.066163                  0.661342   \n",
       "2        1.708639      3.735404    -0.018884                 -1.512077   \n",
       "3        0.843796      4.663484     0.347440                 -1.512077   \n",
       "4        1.132077     -0.433591    -0.151547                  0.661342   \n",
       "5        1.132077      0.796483    -0.731865                  0.661342   \n",
       "6        1.132077      1.555152    -1.407847                 -1.512077   \n",
       "7       -0.885891      0.752289    -0.325042                  0.661342   \n",
       "8        1.420358      0.258786    -2.457153                  0.661342   \n",
       "9        1.708639     -0.455688    -1.476179                  0.661342   \n",
       "10       1.420358      1.437301    -0.235045                  0.661342   \n",
       "11       0.555515      0.936432     1.667405                 -1.512077   \n",
       "12       1.420358      3.610187    -0.361875                  0.661342   \n",
       "13      -0.021047      3.448141     1.045755                  0.661342   \n",
       "14      -0.309329      4.302564     0.391939                 -1.512077   \n",
       "15      -1.462453      2.254895    -0.032883                  0.661342   \n",
       "16      -0.309329      4.751873     0.768762                  0.661342   \n",
       "17      -0.309329     -0.256814     1.228083                  0.661342   \n",
       "18      -1.174172     -0.455688    -1.390514                 -1.512077   \n",
       "19       1.420358      2.652644     0.650432                  0.661342   \n",
       "20       1.708639      2.063386    -2.983972                  0.661342   \n",
       "21      -0.309329     -0.851964     1.563908                  0.661342   \n",
       "22       0.555515      0.096740     1.201917                  0.661342   \n",
       "23       1.132077      1.636175     0.117613                  0.661342   \n",
       "24      -0.309329     -0.470420     0.686098                  0.661342   \n",
       "25      -0.885891      0.074643     1.377746                 -1.512077   \n",
       "26      -0.885891      0.840678     1.747569                 -1.512077   \n",
       "27      -0.597610      0.730192    -2.065496                  0.661342   \n",
       "28       1.132077      2.159141     1.225417                 -1.512077   \n",
       "29      -0.309329      1.231061     0.716263                 -1.512077   \n",
       "...           ...           ...          ...                       ...   \n",
       "2093    -0.021047     -0.168425    -0.064216                  0.661342   \n",
       "2094    -0.597610     -0.411494    -0.504871                  0.661342   \n",
       "2095    -1.462453     -0.057940     0.121946                 -1.512077   \n",
       "2096     0.267234      1.312083    -0.428373                 -1.512077   \n",
       "2097     1.420358     -0.593427     0.066447                  0.661342   \n",
       "2098    -0.885891     -0.731166    -0.014717                  0.661342   \n",
       "2099     1.420358     -0.315740     2.049728                  0.661342   \n",
       "2100    -0.885891     -0.043208     0.634932                  0.661342   \n",
       "2101    -0.597610     -0.647197     0.707597                  0.661342   \n",
       "2102    -1.462453      0.244055     1.205750                 -1.512077   \n",
       "2103    -1.174172     -0.396763     0.798095                  0.661342   \n",
       "2104    -1.462453     -0.795984     0.596767                 -1.512077   \n",
       "2105    -0.021047     -0.718644    -0.373374                  0.661342   \n",
       "2106     1.420358     -0.635412     0.672598                  0.661342   \n",
       "2107    -0.309329     -0.389397     1.209584                 -1.512077   \n",
       "2108    -0.885891     -0.630992    -0.130048                  0.661342   \n",
       "2109     0.843796     -0.374665    -0.074882                  0.661342   \n",
       "2110     0.555515      1.245792     1.112086                 -1.512077   \n",
       "2111     1.420358      0.700729     0.068114                  0.661342   \n",
       "2112     0.267234     -0.569120    -0.558370                 -1.512077   \n",
       "2113    -1.462453     -0.256814    -1.756504                  0.661342   \n",
       "2114    -1.462453     -0.606686    -0.076382                 -1.512077   \n",
       "2115    -1.174172     -0.448323     0.169778                 -1.512077   \n",
       "2116    -1.462453     -0.681079    -0.652367                 -1.512077   \n",
       "2117    -0.885891     -0.183157    -0.534203                  0.661342   \n",
       "2118     1.132077     -0.396763     0.444604                  0.661342   \n",
       "2119    -1.462453     -0.433591     0.050781                  0.661342   \n",
       "2120     1.132077     -0.532292    -0.329876                  0.661342   \n",
       "2121    -1.462453      0.273518     0.169945                  0.661342   \n",
       "2122    -0.309329      1.407838     0.292441                  0.661342   \n",
       "\n",
       "      seg_duration_range  ...  sec_key_range  liveness  time_signature  \\\n",
       "0              -0.399516  ...      -0.114207 -0.114207       -0.751827   \n",
       "1              -0.250176  ...      -0.616202 -0.616202       -0.902028   \n",
       "2              -0.360216  ...      -0.614479 -0.614479        0.348017   \n",
       "3              -0.175506  ...      -1.294138 -1.294138       -0.875000   \n",
       "4               0.614424  ...      -0.860099 -0.860099       -0.646890   \n",
       "5              -0.301266  ...      -0.300452 -0.300452       -0.499783   \n",
       "6               0.048504  ...      -1.064762 -1.064762       -0.968621   \n",
       "7              -0.037956  ...      -0.798268 -0.798268       -0.822735   \n",
       "8              -0.049746  ...      -1.318813 -1.318813       -1.190055   \n",
       "9              -0.085116  ...       0.187176  0.187176       -0.600975   \n",
       "10             -0.254106  ...      -1.115170 -1.115170       -0.707540   \n",
       "11             -0.258036  ...      -0.772753 -0.772753       -0.950873   \n",
       "12             -0.470256  ...      -0.523113 -0.523113       -0.409255   \n",
       "13              0.649794  ...      -1.150751 -1.150751       -0.234469   \n",
       "14              0.370764  ...      -0.667729 -0.667729       -1.188264   \n",
       "15              0.013134  ...      -1.094205 -1.094205       -1.561364   \n",
       "16              0.001344  ...      -1.434449 -1.434449       -0.304400   \n",
       "17              0.288234  ...       0.015848  0.015848        1.067677   \n",
       "18             -0.159786  ...      -0.256018 -0.256018        0.172335   \n",
       "19             -0.053676  ...      -1.202934 -1.202934       -0.177238   \n",
       "20             -0.489906  ...      -0.945738 -0.945738        0.911941   \n",
       "21             -0.588156  ...      -0.863883 -0.863883        0.966729   \n",
       "22             -0.128346  ...      -0.103978 -0.103978       -0.056019   \n",
       "23             -0.238386  ...       1.042614  1.042614        0.015621   \n",
       "24              0.614424  ...      -0.756540 -0.756540        0.460036   \n",
       "25              3.271104  ...      -1.276494 -1.276494       -1.036679   \n",
       "26              0.417924  ...      -0.008681 -0.008681        0.018064   \n",
       "27              0.131034  ...      -0.353466 -0.353466       -0.829899   \n",
       "28             -0.226596  ...      -1.087017 -1.087017       -0.250507   \n",
       "29              0.068154  ...      -0.389206 -0.389206        0.683261   \n",
       "...                  ...  ...            ...       ...             ...   \n",
       "2093            0.032784  ...       0.299288  0.299288       -0.877768   \n",
       "2094            0.111384  ...       0.312622  0.312622       -0.259787   \n",
       "2095           -0.482046  ...       0.247543  0.247543       -0.226979   \n",
       "2096            0.370764  ...      -0.303337 -0.303337        0.114127   \n",
       "2097           -0.285546  ...       0.735474  0.735474       -0.462334   \n",
       "2098            0.881664  ...       0.495925  0.495925       -0.667812   \n",
       "2099           -0.340566  ...      -0.701146 -0.701146       -1.102051   \n",
       "2100           -0.065466  ...      -0.779343 -0.779343       -0.845204   \n",
       "2101           -0.356286  ...       0.618933  0.618933        0.264897   \n",
       "2102           -0.348426  ...      -0.373298 -0.373298       -1.345059   \n",
       "2103           -0.151926  ...      -0.555406 -0.555406        1.802480   \n",
       "2104           -0.344496  ...       1.006400  1.006400        0.246987   \n",
       "2105            0.103524  ...      -0.219846 -0.219846       -1.181262   \n",
       "2106           -0.395586  ...       0.473708  0.473708       -0.392322   \n",
       "2107           -0.061536  ...      -0.165159 -0.165159       -1.053449   \n",
       "2108           -0.116556  ...       1.221345  1.221345       -0.167062   \n",
       "2109           -0.395586  ...       0.201369  0.201369       -0.427573   \n",
       "2110            0.296094  ...      -0.287199 -0.287199       -1.454310   \n",
       "2111           -0.030096  ...      -0.289753 -0.289753       -0.518100   \n",
       "2112           -0.191226  ...      -0.748963 -0.748963       -0.713483   \n",
       "2113           -0.293406  ...      -0.518550 -0.518550       -0.256938   \n",
       "2114            0.508314  ...       0.438147  0.438147        1.703486   \n",
       "2115           -0.395586  ...      -1.053474 -1.053474       -1.084385   \n",
       "2116            0.099594  ...      -0.289696 -0.289696        0.182511   \n",
       "2117            0.072084  ...       1.024898  1.024898       -0.222583   \n",
       "2118           -0.293406  ...       1.797904  1.797904       -0.151594   \n",
       "2119            0.555474  ...       0.619263  0.619263       -0.830713   \n",
       "2120            0.127104  ...      -0.247589 -0.247589       -0.699643   \n",
       "2121           -0.324846  ...       0.935717  0.935717        1.595049   \n",
       "2122           -0.226596  ...       0.694435  0.694435        1.655048   \n",
       "\n",
       "      sec_mode_range  sec_duration_range  no_unique_pitches  no_segments  \\\n",
       "0          -0.206105           -0.293466           0.466921    -0.695168   \n",
       "1          -0.585274           -0.550939           0.466921    -0.695168   \n",
       "2           0.552233           -0.621966           0.466921    -0.695168   \n",
       "3           0.173064           -0.641776           0.466921     0.617859   \n",
       "4          -1.343613           -0.608379          -2.141691    -0.695168   \n",
       "5          -0.206105           -0.515867           0.466921     1.274372   \n",
       "6           0.931402           -0.635773           0.466921     0.617859   \n",
       "7          -0.585274           -0.567937           0.466921    -1.351682   \n",
       "8          -0.585274           -0.793056          -2.141691    -0.695168   \n",
       "9           0.552233            1.006568           0.466921     0.617859   \n",
       "10          0.552233           -0.684399          -2.141691    -0.038655   \n",
       "11         -0.585274           -0.758016           0.466921     1.274372   \n",
       "12          0.552233           -0.788317           0.466921    -0.038655   \n",
       "13         -1.722782           -0.653403           0.466921    -0.695168   \n",
       "14         -0.585274            0.307293           0.466921    -0.695168   \n",
       "15         -1.343613           -0.745789           0.466921    -1.351682   \n",
       "16         -0.964443           -0.754225           0.466921    -1.351682   \n",
       "17          0.931402           -0.476878           0.466921    -0.038655   \n",
       "18          0.552233            0.464355           0.466921     1.274372   \n",
       "19         -0.964443           -0.625599          -2.141691    -0.038655   \n",
       "20         -0.585274           -0.713593          -2.141691     0.617859   \n",
       "21          0.931402           -0.432013          -2.141691    -0.038655   \n",
       "22         -0.206105           -0.705378           0.466921    -0.695168   \n",
       "23          0.931402            0.756931           0.466921     1.274372   \n",
       "24          0.552233           -0.548790           0.466921    -0.038655   \n",
       "25         -0.585274           -0.742566           0.466921    -1.351682   \n",
       "26          0.552233            0.722491           0.466921     1.274372   \n",
       "27         -1.722782           -0.578585          -2.141691    -0.038655   \n",
       "28          0.173064           -0.444904           0.466921    -0.695168   \n",
       "29          0.931402           -0.586326           0.466921    -0.695168   \n",
       "...              ...                 ...                ...          ...   \n",
       "2093       -1.343613           -0.598711           0.466921    -1.351682   \n",
       "2094        0.552233           -0.500038           0.466921     0.617859   \n",
       "2095        0.552233           -0.547210           0.466921     1.274372   \n",
       "2096        0.552233            1.815100           0.466921    -0.695168   \n",
       "2097        0.552233           -0.514604          -2.141691    -1.351682   \n",
       "2098        0.173064           -0.355930           0.466921    -0.695168   \n",
       "2099       -0.585274           -0.329264           0.466921    -0.695168   \n",
       "2100       -0.585274           -0.410054           0.466921    -1.351682   \n",
       "2101        0.931402           -0.186167           0.466921     0.617859   \n",
       "2102       -0.585274           -0.739470           0.466921     0.617859   \n",
       "2103        0.552233           -0.500228           0.466921    -0.038655   \n",
       "2104        0.552233           -0.159500           0.466921     0.617859   \n",
       "2105       -0.206105           -0.707748           0.466921     0.617859   \n",
       "2106       -0.206105           -0.265567           0.466921     0.617859   \n",
       "2107        0.931402           -0.632834           0.466921    -0.695168   \n",
       "2108        0.173064           -0.169832           0.466921    -0.695168   \n",
       "2109        0.931402           -0.279564           0.466921    -0.695168   \n",
       "2110       -2.101951           -0.605852           0.466921    -1.351682   \n",
       "2111        0.552233           -0.424840           0.466921    -0.038655   \n",
       "2112        0.931402           -0.204840           0.466921     1.274372   \n",
       "2113        0.173064           -0.422123           0.466921    -0.038655   \n",
       "2114        0.552233           -0.666168           0.466921    -0.038655   \n",
       "2115       -0.206105            1.970898           0.466921    -1.351682   \n",
       "2116        0.552233           -0.730812           0.466921     0.617859   \n",
       "2117       -0.585274            1.418290           0.466921     1.274372   \n",
       "2118        0.931402            1.562777           0.466921     0.617859   \n",
       "2119        0.931402           -0.604841           0.466921    -0.695168   \n",
       "2120        0.173064           -0.518079           0.466921     1.274372   \n",
       "2121        0.173064           -0.542566           0.466921     0.617859   \n",
       "2122        0.552233           -0.620891           0.466921    -1.351682   \n",
       "\n",
       "      mean_pitch      mode  no_sections  \n",
       "0      -0.311422 -0.049848    -0.230527  \n",
       "1      -0.477337 -1.275272    -0.303023  \n",
       "2       0.131017 -0.301217     0.188947  \n",
       "3      -0.138594 -0.254085     0.222484  \n",
       "4      -0.581033 -0.615428    -0.555043  \n",
       "5       0.587282  0.484312     0.517400  \n",
       "6      -1.085690  0.500022    -1.069639  \n",
       "7       0.310758 -0.364059     0.349508  \n",
       "8      -3.083578 -0.772534    -3.736436  \n",
       "9       0.213974  0.028705     0.239879  \n",
       "10     -0.601773 -0.552586    -0.562545  \n",
       "11     -0.339074 -0.992481     0.021379  \n",
       "12     -1.217039 -1.479509    -1.024897  \n",
       "13     -0.850644 -0.929639    -0.727588  \n",
       "14     -0.947428 -0.961060    -0.894225  \n",
       "15     -1.929089 -0.961060    -1.647087  \n",
       "16     -0.663991 -0.929639    -0.346604  \n",
       "17      0.843067  0.939918     0.857479  \n",
       "18     -0.504989 -0.364059    -0.413555  \n",
       "19     -1.210126 -0.772534    -0.860591  \n",
       "20     -0.615599 -1.463798     0.038030  \n",
       "21     -0.131681 -0.474033    -0.203547  \n",
       "22      0.732457 -0.049848     0.809527  \n",
       "23      1.008982  1.442656     1.020704  \n",
       "24      0.677152  0.358627     0.632663  \n",
       "25     -0.601773 -1.432377    -0.311881  \n",
       "26      0.808501  0.012995     0.815018  \n",
       "27     -1.258518  1.332682    -1.319917  \n",
       "28      0.587282  0.028705     0.613579  \n",
       "29      0.552716  0.955629     0.479976  \n",
       "...          ...       ...          ...  \n",
       "2093    0.863806  3.265082     0.814212  \n",
       "2094    0.573456  1.505498     0.610308  \n",
       "2095    1.002069  0.390048     0.976658  \n",
       "2096    0.725544  0.154390     0.650864  \n",
       "2097    0.822328  1.285550     0.813649  \n",
       "2098    0.677152  2.479553     0.615333  \n",
       "2099    0.898372  1.772578     0.865535  \n",
       "2100   -0.276856 -0.238374    -0.426454  \n",
       "2101    1.015895  1.913973     1.030863  \n",
       "2102   -0.290683  0.138679    -0.241711  \n",
       "2103    0.317671 -0.316927     0.285957  \n",
       "2104    0.953677  0.484312     0.955101  \n",
       "2105   -0.511902  0.861365    -0.346240  \n",
       "2106    0.995155  1.536919     0.985057  \n",
       "2107    0.462846  0.924207     0.404680  \n",
       "2108    0.359149  0.028705     0.276800  \n",
       "2109    0.919111  2.008236     0.914912  \n",
       "2110   -1.223952 -0.254085    -1.289781  \n",
       "2111    0.801588  0.625707     0.753081  \n",
       "2112    0.870719  1.364103     0.901741  \n",
       "2113   -0.304509 -0.065558    -0.371060  \n",
       "2114    0.511238  0.484312     0.516311  \n",
       "2115   -1.521216  0.185811    -1.484993  \n",
       "2116   -0.186986 -0.536875    -0.372050  \n",
       "2117    0.635674  1.175576     0.579253  \n",
       "2118    1.029721  1.144155     1.009913  \n",
       "2119    0.220887  0.719970     0.260385  \n",
       "2120    0.780849  0.704260     0.792368  \n",
       "2121    0.704805  1.081313     0.646645  \n",
       "2122    0.836154  0.798523     0.852893  \n",
       "\n",
       "[2123 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaling data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X))\n",
    "columns = set(data.columns) - {'ballet'}\n",
    "X_scaled.columns = columns\n",
    "X_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Used All Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate models\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluation(y_test, y_pred):\n",
    "    print('classification report: \\n')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))\n",
    "    print(\"Accuracy score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Models\n",
    "All data thrown into the basic model, just to see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier -- Used for Baseline Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.55      0.52       215\n",
      "           1       0.49      0.44      0.47       210\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       425\n",
      "   macro avg       0.50      0.50      0.49       425\n",
      "weighted avg       0.50      0.50      0.50       425\n",
      "\n",
      "ROC AUC: 0.4958471760797342\n",
      "Accuracy score: 0.4964705882352941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "dc = DummyClassifier()\n",
    "dc.fit(X_train, y_train)\n",
    "y_pred = dc.predict(X_test)\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# use scaled data for interpretability\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_unique_timbres': -0.0809215629759104,\n",
       " 'tempo': 0.1298113896062884,\n",
       " 'valence': -1.5970014888784207,\n",
       " 'danceability': -0.06548472702465596,\n",
       " 'instrumentalness': 0.07591734104412191,\n",
       " 'duration_ms': 0.09373171212513265,\n",
       " 'acousticness': 0.3981428317384476,\n",
       " 'speechiness': -0.03295304071578723,\n",
       " 'sec_time_signature_range': 0.16578279981599361,\n",
       " 'seg_duration_range': 0.04261170554647233,\n",
       " 'sec_tempo_range': 0.0780097898424133,\n",
       " 'sec_loudness_range': 0.031085584769035186,\n",
       " 'energy': -0.1802578782587597,\n",
       " 'key': 0.5490815555359821,\n",
       " 'loudness': -1.422808074514123,\n",
       " 'sec_key_range': -0.24980193734109948,\n",
       " 'liveness': -0.24980193734109948,\n",
       " 'time_signature': -0.18187726723275513,\n",
       " 'sec_mode_range': 0.06124123946409796,\n",
       " 'sec_duration_range': 0.16561093760674808,\n",
       " 'no_unique_pitches': -0.10238250404269321,\n",
       " 'no_segments': 0.045884099709049685,\n",
       " 'mean_pitch': 0.7870807881945402,\n",
       " 'mode': -0.6302631460934892,\n",
       " 'no_sections': -0.49703779968968487}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = {X_scaled.columns[i]: lr.coef_[0][i] for i in range (len(lr.coef_[0]))}\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80       215\n",
      "           1       0.79      0.80      0.80       210\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       425\n",
      "   macro avg       0.80      0.80      0.80       425\n",
      "weighted avg       0.80      0.80      0.80       425\n",
      "\n",
      "ROC AUC: 0.7954042081949059\n",
      "Accuracy score: 0.7952941176470588\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that was unexpected... It's surprisingly high without being so eerily accurate that I suspect overfitting... Let's see how all the other models fair!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "knc.fit(X_train, y_train)\n",
    "y_pred = knc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       215\n",
      "           1       0.80      0.75      0.78       210\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       425\n",
      "   macro avg       0.79      0.79      0.79       425\n",
      "weighted avg       0.79      0.79      0.79       425\n",
      "\n",
      "ROC AUC: 0.7854928017718714\n",
      "Accuracy score: 0.7858823529411765\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to use scaled data for SVMs\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       215\n",
      "           1       0.81      0.82      0.82       210\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       425\n",
      "   macro avg       0.82      0.82      0.82       425\n",
      "weighted avg       0.82      0.82      0.82       425\n",
      "\n",
      "ROC AUC: 0.8165559246954597\n",
      "Accuracy score: 0.8164705882352942\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       215\n",
      "           1       0.81      0.77      0.79       210\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       425\n",
      "   macro avg       0.80      0.80      0.80       425\n",
      "weighted avg       0.80      0.80      0.80       425\n",
      "\n",
      "ROC AUC: 0.7996677740863787\n",
      "Accuracy score: 0.8\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/84/4e2cae6247f397f83d8adc5c2a2a0c5d7d790a14a4c7400ff6574586f589/xgboost-0.90.tar.gz (676kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 686kB 6.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/hannah/anaconda3/lib/python3.7/site-packages (from xgboost) (1.16.2)\n",
      "Requirement already satisfied: scipy in /Users/hannah/anaconda3/lib/python3.7/site-packages (from xgboost) (1.2.1)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Building wheel for xgboost (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/hannah/Library/Caches/pip/wheels/e9/48/4d/de4187b5270dff71d3697c5a7857a1e2d9a0c63a28b3462eeb\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use the train and test from Random Forest\n",
    "xgbc = xgb.XGBRFClassifier()\n",
    "xgbc.fit(X_train, y_train)\n",
    "y_pred = xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       215\n",
      "           1       0.80      0.82      0.81       210\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       425\n",
      "   macro avg       0.81      0.81      0.81       425\n",
      "weighted avg       0.81      0.81      0.81       425\n",
      "\n",
      "ROC AUC: 0.8095238095238095\n",
      "Accuracy score: 0.8094117647058824\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning & Visualizations\n",
    "- tuning parameters for each model\n",
    "- visualizing ROC-AUC, feature importance (for interpretable models - logistic regression & random forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Two grid searches were done -- one with l1 and l2 as penalty for the lbfgs solver, and the other with just l2, and the other solvers, since the other solvers only take l2 as the penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# use scaled data for interpretability\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['liblinear'],\n",
    "    'max_iter': [200, 500, 800, 1200, 1600]}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       215\n",
      "           1       0.79      0.80      0.80       210\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       425\n",
      "   macro avg       0.80      0.80      0.80       425\n",
      "weighted avg       0.80      0.80      0.80       425\n",
      "\n",
      "ROC AUC: 0.7977297895902546\n",
      "Accuracy score: 0.7976470588235294\n",
      "None\n",
      "{'C': 0.615848211066026, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 348 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1465 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1925 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2353 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2493 out of 2500 | elapsed:  1.9min remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       215\n",
      "           1       0.79      0.80      0.80       210\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       425\n",
      "   macro avg       0.80      0.80      0.80       425\n",
      "weighted avg       0.80      0.80      0.80       425\n",
      "\n",
      "ROC AUC: 0.7977297895902546\n",
      "Accuracy score: 0.7976470588235294\n",
      "None\n",
      "{'C': 4.281332398719396, 'max_iter': 200, 'penalty': 'l2', 'solver': 'sag'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:  1.9min finished\n",
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# use scaled data for interpretability\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {'penalty' : ['l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [200, 500, 800, 1200, 1600]}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes some sense that the maximum iterations that winds up with the best results is 200, since more than that may overfit to the training data. So we'll keep max_iter=200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:    4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       215\n",
      "           1       0.79      0.81      0.80       210\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       425\n",
      "   macro avg       0.80      0.80      0.80       425\n",
      "weighted avg       0.80      0.80      0.80       425\n",
      "\n",
      "ROC AUC: 0.800110741971207\n",
      "Accuracy score: 0.8\n",
      "None\n",
      "{'C': 1438.44988828766, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    5.5s finished\n",
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# use scaled data for interpretability\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {'penalty' : ['l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, because it doesn't converge, you get different values for C every time, so it looks like we should stick with `{'C': 0.615848211066026, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}` as the parameters for the best-tuned Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77       215\n",
      "           1       0.76      0.76      0.76       210\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       425\n",
      "   macro avg       0.76      0.76      0.76       425\n",
      "weighted avg       0.76      0.76      0.76       425\n",
      "\n",
      "ROC AUC: 0.7646179401993355\n",
      "Accuracy score: 0.7647058823529411\n",
      "None\n",
      "{'n_neighbors': 9, 'p': 2, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:   10.5s finished\n"
     ]
    }
   ],
   "source": [
    "# use scaled data for interpretability\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {'n_neighbors': list(range(1, 30, 2)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2, 3]}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(KNeighborsClassifier() , param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817432273262662"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       215\n",
      "           1       0.84      0.80      0.82       210\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       425\n",
      "   macro avg       0.82      0.82      0.82       425\n",
      "weighted avg       0.82      0.82      0.82       425\n",
      "\n",
      "ROC AUC: 0.8232004429678847\n",
      "Accuracy score: 0.8235294117647058\n",
      "None\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# need to use scaled data for SVMs\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'C':[1,10,100,1000],\n",
    "              'gamma':[1,0.1,0.001,0.0001], \n",
    "              'kernel':['linear','rbf'] \n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(SVC(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       215\n",
      "           1       0.84      0.80      0.82       210\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       425\n",
      "   macro avg       0.82      0.82      0.82       425\n",
      "weighted avg       0.82      0.82      0.82       425\n",
      "\n",
      "ROC AUC: 0.8232004429678847\n",
      "Accuracy score: 0.8235294117647058\n",
      "None\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# need to use scaled data for SVMs\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'C':[1000, 1500],\n",
    "              'gamma':[1,0.1,0.001], \n",
    "              'kernel':['linear','rbf'] \n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(SVC(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       215\n",
      "           1       0.84      0.80      0.82       210\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       425\n",
      "   macro avg       0.82      0.82      0.82       425\n",
      "weighted avg       0.82      0.82      0.82       425\n",
      "\n",
      "ROC AUC: 0.8232004429678847\n",
      "Accuracy score: 0.8235294117647058\n",
      "None\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# need to use scaled data for SVMs\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'C':[1000, 1500],\n",
    "              'gamma':[1,0.1,0.001], \n",
    "              'kernel':['rbf', 'sigmoid', 'poly'] \n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(SVC(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       215\n",
      "           1       0.81      0.83      0.82       210\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       425\n",
      "   macro avg       0.82      0.82      0.82       425\n",
      "weighted avg       0.82      0.82      0.82       425\n",
      "\n",
      "ROC AUC: 0.8213178294573644\n",
      "Accuracy score: 0.8211764705882353\n",
      "None\n",
      "{'max_depth': 10, 'max_features': 16, 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'max_depth': [1, 10],\n",
    "            'max_features': [1, 2, 4, 16],\n",
    "            'min_samples_leaf': [2, 10, 100, 500, 1000],\n",
    "            'min_samples_split': [2, 10, 100, 500, 1000],\n",
    "            'n_estimators': [100, 500, 1000]\n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed: 15.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       215\n",
      "           1       0.81      0.81      0.81       210\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       425\n",
      "   macro avg       0.81      0.81      0.81       425\n",
      "weighted avg       0.81      0.81      0.81       425\n",
      "\n",
      "ROC AUC: 0.8094130675526024\n",
      "Accuracy score: 0.8094117647058824\n",
      "None\n",
      "{'max_depth': 10, 'max_features': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'max_depth': [5, 10, 15],\n",
    "            'max_features': [10, 15, 20],\n",
    "            'min_samples_leaf': [2, 10, 30, 50, 70],\n",
    "            'min_samples_split': [2, 10, 30, 50],\n",
    "            'n_estimators': [50, 100, 150, 200]\n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       215\n",
      "           1       0.81      0.81      0.81       210\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       425\n",
      "   macro avg       0.81      0.81      0.81       425\n",
      "weighted avg       0.81      0.81      0.81       425\n",
      "\n",
      "ROC AUC: 0.8117940199335548\n",
      "Accuracy score: 0.8117647058823529\n",
      "None\n",
      "{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'max_depth': [3, 10, 100], \n",
    "              'learning_rate': [.01, .1, 1, 10], \n",
    "              'n_estimators': [10, 100, 1000]\n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(xgb.XGBRFClassifier(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       215\n",
      "           1       0.81      0.81      0.81       210\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       425\n",
      "   macro avg       0.81      0.81      0.81       425\n",
      "weighted avg       0.81      0.81      0.81       425\n",
      "\n",
      "ROC AUC: 0.8117940199335548\n",
      "Accuracy score: 0.8117647058823529\n",
      "None\n",
      "{'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'max_depth': [5, 10, 20, 50], \n",
    "              'learning_rate': [.001, .01, .1], \n",
    "              'n_estimators': [10, 100, 200, 500]\n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(xgb.XGBRFClassifier(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "- PCA\n",
    "- Regularization\n",
    "- New visuals if better models are found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1feacc88>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(list(range(len(pca.components_))), pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_ms                 301823.882778\n",
       "no_segments                    898.969507\n",
       "no_unique_pitches               95.496126\n",
       "no_unique_timbres               42.116657\n",
       "seg_duration_range              16.076368\n",
       "sec_duration_range              16.076368\n",
       "no_sections                     12.340037\n",
       "sec_tempo_range                  8.011455\n",
       "sec_loudness_range               7.083860\n",
       "sec_key_range                    1.300521\n",
       "sec_time_signature_range         0.808913\n",
       "loudness                         0.309948\n",
       "sec_mode_range                   0.128857\n",
       "mean_pitch                       0.030941\n",
       "time_signature                   0.022994\n",
       "instrumentalness                 0.019996\n",
       "speechiness                     -0.000812\n",
       "acousticness                    -0.002503\n",
       "energy                          -0.010905\n",
       "liveness                        -0.018994\n",
       "mode                            -0.027267\n",
       "danceability                    -0.052376\n",
       "valence                         -0.087926\n",
       "key                             -0.117994\n",
       "tempo                           -3.767942\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "no_segments                 214.234664\n",
       "no_unique_pitches            44.485707\n",
       "no_unique_timbres            11.904579\n",
       "tempo                         4.091775\n",
       "sec_tempo_range               2.246297\n",
       "loudness                      1.691175\n",
       "no_sections                   0.477680\n",
       "sec_key_range                 0.264922\n",
       "seg_duration_range            0.238958\n",
       "sec_duration_range            0.238958\n",
       "key                           0.111294\n",
       "sec_mode_range                0.036103\n",
       "valence                       0.035843\n",
       "time_signature                0.034727\n",
       "energy                        0.034337\n",
       "danceability                  0.027834\n",
       "sec_time_signature_range      0.015771\n",
       "mean_pitch                    0.014361\n",
       "acousticness                  0.006197\n",
       "liveness                      0.004083\n",
       "speechiness                   0.001068\n",
       "mode                         -0.005645\n",
       "instrumentalness             -0.026586\n",
       "sec_loudness_range           -0.455563\n",
       "duration_ms                  -0.653871\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "no_segments                 21.587505\n",
       "tempo                        0.583855\n",
       "key                          0.085625\n",
       "valence                      0.056619\n",
       "danceability                 0.026620\n",
       "mode                         0.020799\n",
       "liveness                     0.008565\n",
       "acousticness                 0.001731\n",
       "speechiness                  0.000177\n",
       "energy                      -0.010581\n",
       "time_signature              -0.014065\n",
       "instrumentalness            -0.028942\n",
       "duration_ms                 -0.029718\n",
       "mean_pitch                  -0.032601\n",
       "sec_mode_range              -0.123760\n",
       "no_sections                 -0.123963\n",
       "sec_time_signature_range    -0.371437\n",
       "loudness                    -0.561501\n",
       "sec_key_range               -0.958087\n",
       "sec_loudness_range          -3.690591\n",
       "sec_tempo_range             -4.649576\n",
       "seg_duration_range          -4.873759\n",
       "sec_duration_range          -4.873759\n",
       "no_unique_timbres          -18.397849\n",
       "no_unique_pitches          -98.814390\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "no_unique_timbres           42.301500\n",
       "sec_duration_range           1.231638\n",
       "seg_duration_range           1.231638\n",
       "sec_tempo_range              0.903856\n",
       "sec_loudness_range           0.433573\n",
       "sec_key_range                0.301150\n",
       "sec_time_signature_range     0.246063\n",
       "no_sections                  0.146372\n",
       "sec_mode_range               0.042277\n",
       "acousticness                 0.032434\n",
       "key                          0.026972\n",
       "speechiness                  0.002661\n",
       "instrumentalness            -0.001300\n",
       "duration_ms                 -0.001811\n",
       "mode                        -0.003426\n",
       "mean_pitch                  -0.003579\n",
       "danceability                -0.004947\n",
       "time_signature              -0.005618\n",
       "liveness                    -0.018016\n",
       "energy                      -0.036739\n",
       "valence                     -0.052796\n",
       "no_segments                 -0.576084\n",
       "loudness                    -1.478923\n",
       "tempo                       -3.777604\n",
       "no_unique_pitches           -8.200017\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sec_tempo_range             26.641492\n",
       "seg_duration_range           6.479259\n",
       "sec_duration_range           6.479259\n",
       "sec_loudness_range           2.065633\n",
       "no_segments                  0.400488\n",
       "sec_time_signature_range     0.217691\n",
       "sec_key_range                0.028791\n",
       "key                          0.010207\n",
       "sec_mode_range               0.002716\n",
       "instrumentalness             0.000581\n",
       "speechiness                  0.000427\n",
       "mean_pitch                  -0.000496\n",
       "duration_ms                 -0.001972\n",
       "acousticness                -0.004451\n",
       "liveness                    -0.005514\n",
       "energy                      -0.005686\n",
       "time_signature              -0.014441\n",
       "mode                        -0.019081\n",
       "valence                     -0.023542\n",
       "danceability                -0.025019\n",
       "no_sections                 -0.310756\n",
       "loudness                    -0.430778\n",
       "no_unique_pitches           -1.509702\n",
       "no_unique_timbres           -2.390384\n",
       "tempo                      -12.541335\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tempo                       27.038030\n",
       "sec_tempo_range             12.813746\n",
       "no_unique_timbres            1.948763\n",
       "sec_loudness_range           0.942761\n",
       "loudness                     0.282190\n",
       "no_sections                  0.262186\n",
       "sec_key_range                0.044481\n",
       "valence                      0.016963\n",
       "danceability                 0.011957\n",
       "energy                       0.005959\n",
       "mode                         0.005794\n",
       "speechiness                  0.001732\n",
       "duration_ms                  0.001670\n",
       "mean_pitch                  -0.000554\n",
       "sec_mode_range              -0.000912\n",
       "acousticness                -0.002163\n",
       "time_signature              -0.002936\n",
       "liveness                    -0.005490\n",
       "instrumentalness            -0.016236\n",
       "seg_duration_range          -0.045195\n",
       "sec_duration_range          -0.045195\n",
       "sec_time_signature_range    -0.053189\n",
       "key                         -0.062946\n",
       "no_segments                 -0.560162\n",
       "no_unique_pitches           -0.961336\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sec_duration_range          14.988742\n",
       "seg_duration_range          14.988742\n",
       "tempo                        2.937330\n",
       "no_segments                  0.216520\n",
       "loudness                     0.203669\n",
       "time_signature               0.025224\n",
       "energy                       0.007710\n",
       "valence                      0.002303\n",
       "speechiness                  0.000892\n",
       "mode                         0.000660\n",
       "danceability                 0.000350\n",
       "mean_pitch                  -0.000599\n",
       "liveness                    -0.001079\n",
       "duration_ms                 -0.001577\n",
       "acousticness                -0.002122\n",
       "sec_mode_range              -0.010073\n",
       "instrumentalness            -0.015471\n",
       "sec_time_signature_range    -0.028465\n",
       "sec_key_range               -0.116661\n",
       "key                         -0.161462\n",
       "sec_loudness_range          -0.414113\n",
       "no_unique_timbres           -0.654595\n",
       "no_unique_pitches           -0.992383\n",
       "no_sections                 -1.307976\n",
       "sec_tempo_range             -6.005486\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sec_loudness_range          9.021966\n",
       "loudness                    0.313459\n",
       "sec_key_range               0.296737\n",
       "no_sections                 0.151208\n",
       "no_segments                 0.084970\n",
       "sec_time_signature_range    0.061484\n",
       "instrumentalness            0.019603\n",
       "sec_mode_range              0.014492\n",
       "tempo                       0.013820\n",
       "time_signature              0.006836\n",
       "duration_ms                -0.000351\n",
       "mean_pitch                 -0.000461\n",
       "acousticness               -0.001098\n",
       "speechiness                -0.001322\n",
       "energy                     -0.006025\n",
       "danceability               -0.007753\n",
       "liveness                   -0.009001\n",
       "mode                       -0.013616\n",
       "key                        -0.022013\n",
       "sec_duration_range         -0.023837\n",
       "seg_duration_range         -0.023837\n",
       "valence                    -0.024657\n",
       "no_unique_timbres          -0.117363\n",
       "no_unique_pitches          -0.266207\n",
       "sec_tempo_range            -0.702329\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "no_sections                 0.259409\n",
       "sec_time_signature_range    0.213376\n",
       "sec_key_range               0.184592\n",
       "sec_loudness_range          0.172170\n",
       "key                         0.107178\n",
       "tempo                       0.101887\n",
       "no_unique_pitches           0.064590\n",
       "no_segments                 0.037970\n",
       "sec_duration_range          0.024961\n",
       "seg_duration_range          0.024961\n",
       "mode                        0.023772\n",
       "sec_mode_range              0.019560\n",
       "acousticness                0.005066\n",
       "duration_ms                -0.000119\n",
       "speechiness                -0.000419\n",
       "mean_pitch                 -0.000641\n",
       "liveness                   -0.022028\n",
       "time_signature             -0.033374\n",
       "danceability               -0.038432\n",
       "instrumentalness           -0.049069\n",
       "valence                    -0.053275\n",
       "energy                     -0.070212\n",
       "sec_tempo_range            -0.077959\n",
       "no_unique_timbres          -0.175014\n",
       "loudness                   -5.489129\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "key                         3.456143\n",
       "sec_key_range               0.222707\n",
       "loudness                    0.074890\n",
       "seg_duration_range          0.017039\n",
       "sec_duration_range          0.017039\n",
       "tempo                       0.009108\n",
       "danceability                0.003200\n",
       "valence                     0.002694\n",
       "energy                      0.001602\n",
       "liveness                    0.000381\n",
       "mean_pitch                  0.000061\n",
       "duration_ms                 0.000007\n",
       "speechiness                -0.000642\n",
       "no_unique_pitches          -0.001191\n",
       "no_unique_timbres          -0.001454\n",
       "acousticness               -0.001664\n",
       "sec_loudness_range         -0.001722\n",
       "no_sections                -0.002024\n",
       "no_segments                -0.002498\n",
       "sec_tempo_range            -0.004381\n",
       "sec_mode_range             -0.004791\n",
       "sec_time_signature_range   -0.006160\n",
       "instrumentalness           -0.006661\n",
       "time_signature             -0.014013\n",
       "mode                       -0.034705\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sec_loudness_range          0.073752\n",
       "key                         0.067066\n",
       "sec_tempo_range             0.019253\n",
       "no_unique_timbres           0.017917\n",
       "no_unique_pitches           0.015539\n",
       "valence                     0.013270\n",
       "mode                        0.012619\n",
       "tempo                       0.009425\n",
       "time_signature              0.009283\n",
       "danceability                0.006182\n",
       "energy                      0.005441\n",
       "liveness                    0.004143\n",
       "no_segments                 0.002412\n",
       "speechiness                 0.001411\n",
       "duration_ms                 0.000078\n",
       "mean_pitch                  0.000068\n",
       "instrumentalness           -0.003935\n",
       "acousticness               -0.005268\n",
       "sec_mode_range             -0.051370\n",
       "sec_duration_range         -0.084424\n",
       "seg_duration_range         -0.084424\n",
       "loudness                   -0.130875\n",
       "sec_time_signature_range   -0.140343\n",
       "sec_key_range              -1.003947\n",
       "no_sections                -1.981211\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "no_sections                 0.887507\n",
       "key                         0.111988\n",
       "sec_loudness_range          0.043618\n",
       "seg_duration_range          0.032669\n",
       "sec_duration_range          0.032669\n",
       "mode                        0.032604\n",
       "valence                     0.015722\n",
       "no_unique_pitches           0.009678\n",
       "no_unique_timbres           0.008482\n",
       "time_signature              0.008453\n",
       "danceability                0.004750\n",
       "speechiness                 0.000232\n",
       "mean_pitch                 -0.000015\n",
       "duration_ms                -0.000031\n",
       "acousticness               -0.000576\n",
       "liveness                   -0.001567\n",
       "energy                     -0.001838\n",
       "no_segments                -0.002074\n",
       "tempo                      -0.003877\n",
       "sec_tempo_range            -0.007114\n",
       "instrumentalness           -0.012866\n",
       "loudness                   -0.015860\n",
       "sec_mode_range             -0.075452\n",
       "sec_time_signature_range   -0.081860\n",
       "sec_key_range              -1.727979\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sec_time_signature_range    1.154575e+00\n",
       "loudness                    4.186633e-02\n",
       "sec_mode_range              1.297012e-02\n",
       "key                         5.659300e-03\n",
       "tempo                       5.390081e-03\n",
       "liveness                    3.471812e-03\n",
       "no_segments                 4.196548e-04\n",
       "speechiness                 1.142555e-04\n",
       "duration_ms                -2.706277e-07\n",
       "mean_pitch                 -1.648896e-04\n",
       "acousticness               -1.985411e-03\n",
       "no_unique_pitches          -2.061239e-03\n",
       "sec_duration_range         -3.144862e-03\n",
       "seg_duration_range         -3.144862e-03\n",
       "no_unique_timbres          -4.163693e-03\n",
       "energy                     -5.093018e-03\n",
       "sec_tempo_range            -5.279169e-03\n",
       "mode                       -5.611054e-03\n",
       "sec_loudness_range         -6.492731e-03\n",
       "instrumentalness           -6.767343e-03\n",
       "danceability               -3.122195e-02\n",
       "valence                    -3.596883e-02\n",
       "no_sections                -4.527206e-02\n",
       "sec_key_range              -8.007010e-02\n",
       "time_signature             -1.567501e-01\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mode                        1.512077e-02\n",
       "sec_key_range               2.988253e-03\n",
       "no_sections                 2.124118e-03\n",
       "valence                     1.299648e-03\n",
       "sec_loudness_range          1.023584e-03\n",
       "loudness                    7.893863e-04\n",
       "sec_duration_range          6.063801e-04\n",
       "seg_duration_range          6.063801e-04\n",
       "no_unique_timbres           4.332396e-04\n",
       "no_unique_pitches           2.517706e-04\n",
       "no_segments                 3.669118e-05\n",
       "duration_ms                -1.403114e-07\n",
       "sec_tempo_range            -5.379231e-05\n",
       "tempo                      -3.272916e-04\n",
       "mean_pitch                 -3.374208e-04\n",
       "speechiness                -4.821018e-04\n",
       "energy                     -1.679336e-03\n",
       "liveness                   -1.764533e-03\n",
       "danceability               -2.178305e-03\n",
       "key                        -2.969790e-03\n",
       "instrumentalness           -3.621434e-03\n",
       "acousticness               -3.767465e-03\n",
       "sec_mode_range             -1.632010e-02\n",
       "sec_time_signature_range   -9.051285e-02\n",
       "time_signature             -6.703545e-01\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sec_mode_range              1.310135e-01\n",
       "instrumentalness            5.009782e-03\n",
       "liveness                    3.862485e-03\n",
       "energy                      2.308012e-03\n",
       "no_sections                 1.057358e-03\n",
       "speechiness                 4.242590e-04\n",
       "tempo                       2.245789e-04\n",
       "mean_pitch                  1.643586e-04\n",
       "no_segments                 1.732573e-05\n",
       "duration_ms                -6.837525e-08\n",
       "sec_duration_range         -1.680885e-05\n",
       "seg_duration_range         -1.680885e-05\n",
       "no_unique_pitches          -5.308419e-05\n",
       "no_unique_timbres          -9.457624e-05\n",
       "sec_tempo_range            -1.728605e-04\n",
       "sec_loudness_range         -3.900348e-04\n",
       "loudness                   -2.080417e-03\n",
       "key                        -3.415018e-03\n",
       "danceability               -5.004386e-03\n",
       "acousticness               -5.652807e-03\n",
       "sec_time_signature_range   -6.616332e-03\n",
       "valence                    -1.119944e-02\n",
       "time_signature             -1.242717e-02\n",
       "sec_key_range              -1.371688e-02\n",
       "mode                       -4.463450e-01\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "valence                     1.771776e-02\n",
       "sec_mode_range              1.224722e-02\n",
       "danceability                1.028720e-02\n",
       "loudness                    2.746626e-03\n",
       "speechiness                 2.312939e-03\n",
       "sec_key_range               1.802590e-03\n",
       "time_signature              1.728534e-03\n",
       "sec_loudness_range          5.899754e-04\n",
       "no_unique_timbres           8.581717e-05\n",
       "no_unique_pitches           2.505536e-05\n",
       "duration_ms                 2.257791e-07\n",
       "sec_tempo_range            -6.834643e-06\n",
       "no_segments                -7.050095e-05\n",
       "seg_duration_range         -1.682745e-04\n",
       "sec_duration_range         -1.682745e-04\n",
       "tempo                      -2.650539e-04\n",
       "mode                       -4.750813e-04\n",
       "no_sections                -4.989338e-04\n",
       "mean_pitch                 -5.987936e-04\n",
       "key                        -8.086865e-04\n",
       "sec_time_signature_range   -1.020206e-03\n",
       "liveness                   -1.438820e-03\n",
       "energy                     -7.128442e-03\n",
       "acousticness               -2.085784e-02\n",
       "instrumentalness           -3.234153e-01\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "valence                     1.212103e-02\n",
       "sec_key_range               1.148493e-02\n",
       "sec_time_signature_range    4.810056e-03\n",
       "time_signature              4.648279e-03\n",
       "danceability                4.100294e-03\n",
       "speechiness                 1.051557e-03\n",
       "no_sections                 9.805757e-04\n",
       "energy                      3.017064e-04\n",
       "no_unique_timbres           1.944343e-04\n",
       "no_unique_pitches           1.936821e-04\n",
       "duration_ms                -1.804110e-08\n",
       "sec_loudness_range         -7.373613e-06\n",
       "tempo                      -1.042695e-05\n",
       "sec_duration_range         -1.521100e-05\n",
       "seg_duration_range         -1.521100e-05\n",
       "no_segments                -1.644328e-05\n",
       "sec_tempo_range            -3.885118e-05\n",
       "mean_pitch                 -5.259652e-04\n",
       "loudness                   -9.095695e-04\n",
       "acousticness               -1.866510e-03\n",
       "key                        -1.999411e-03\n",
       "liveness                   -5.136387e-03\n",
       "instrumentalness           -9.913171e-03\n",
       "mode                       -8.665861e-02\n",
       "sec_mode_range             -2.917873e-01\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "valence                     1.497548e-01\n",
       "danceability                7.714756e-02\n",
       "energy                      2.957505e-02\n",
       "liveness                    1.376217e-02\n",
       "instrumentalness            1.064547e-02\n",
       "sec_mode_range              7.521739e-03\n",
       "sec_time_signature_range    6.792318e-03\n",
       "speechiness                 2.827197e-03\n",
       "sec_key_range               9.495671e-04\n",
       "mean_pitch                  9.410317e-04\n",
       "sec_loudness_range          4.672944e-04\n",
       "no_sections                 3.276926e-04\n",
       "no_unique_timbres           8.617478e-05\n",
       "seg_duration_range          5.102836e-05\n",
       "sec_duration_range          5.102836e-05\n",
       "no_unique_pitches           2.188044e-05\n",
       "sec_tempo_range             1.236106e-05\n",
       "duration_ms                 7.653272e-08\n",
       "no_segments                -3.104688e-05\n",
       "tempo                      -1.226392e-04\n",
       "key                        -2.019048e-04\n",
       "time_signature             -1.234048e-03\n",
       "mode                       -2.018314e-03\n",
       "loudness                   -2.185799e-03\n",
       "acousticness               -6.739940e-03\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "liveness                    1.276990e-01\n",
       "energy                      1.786863e-02\n",
       "speechiness                 4.773878e-03\n",
       "mode                        1.018933e-03\n",
       "mean_pitch                  6.779940e-04\n",
       "no_sections                 3.893444e-04\n",
       "sec_key_range               1.451858e-04\n",
       "sec_loudness_range          1.215091e-04\n",
       "no_unique_timbres           5.398404e-05\n",
       "seg_duration_range          2.041626e-05\n",
       "sec_duration_range          2.041626e-05\n",
       "tempo                       2.012509e-05\n",
       "sec_tempo_range             5.213402e-06\n",
       "no_segments                 1.058299e-06\n",
       "duration_ms                -2.170956e-08\n",
       "no_unique_pitches          -8.174872e-06\n",
       "key                        -8.230923e-06\n",
       "time_signature             -3.507756e-05\n",
       "instrumentalness           -4.875554e-04\n",
       "loudness                   -5.980599e-04\n",
       "sec_time_signature_range   -8.641600e-04\n",
       "sec_mode_range             -2.967387e-03\n",
       "danceability               -8.593363e-03\n",
       "valence                    -1.173460e-02\n",
       "acousticness               -2.285066e-02\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "energy                      2.457308e-02\n",
       "instrumentalness            4.814727e-03\n",
       "speechiness                 2.900365e-03\n",
       "mode                        1.335724e-03\n",
       "valence                     1.270770e-03\n",
       "time_signature              5.778729e-04\n",
       "sec_mode_range              2.268087e-04\n",
       "no_sections                 2.036035e-04\n",
       "mean_pitch                  1.487494e-04\n",
       "sec_key_range               8.792162e-05\n",
       "no_unique_timbres           6.835585e-05\n",
       "no_segments                 3.340794e-06\n",
       "duration_ms                -2.345296e-08\n",
       "tempo                      -3.028632e-06\n",
       "sec_duration_range         -3.758330e-06\n",
       "seg_duration_range         -3.758330e-06\n",
       "key                        -1.186944e-05\n",
       "sec_tempo_range            -1.902717e-05\n",
       "no_unique_pitches          -1.954482e-05\n",
       "sec_loudness_range         -3.141277e-05\n",
       "loudness                   -2.506854e-04\n",
       "sec_time_signature_range   -2.611365e-04\n",
       "danceability               -1.671151e-02\n",
       "liveness                   -2.035760e-02\n",
       "acousticness               -8.836189e-02\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "danceability                7.153195e-02\n",
       "energy                      1.434397e-02\n",
       "speechiness                 5.696845e-03\n",
       "sec_time_signature_range    7.057107e-04\n",
       "mean_pitch                  5.972951e-04\n",
       "instrumentalness            3.881096e-04\n",
       "mode                        2.123479e-04\n",
       "no_sections                 7.180086e-05\n",
       "sec_tempo_range             1.493952e-05\n",
       "seg_duration_range          5.742777e-06\n",
       "sec_duration_range          5.742777e-06\n",
       "no_unique_pitches           1.686836e-06\n",
       "duration_ms                 3.458103e-09\n",
       "no_segments                -6.531467e-07\n",
       "tempo                      -1.080051e-05\n",
       "key                        -2.759989e-05\n",
       "sec_loudness_range         -3.156270e-05\n",
       "no_unique_timbres          -3.664280e-05\n",
       "sec_key_range              -1.477457e-04\n",
       "loudness                   -2.714208e-04\n",
       "time_signature             -3.698794e-04\n",
       "sec_mode_range             -5.890846e-04\n",
       "liveness                   -2.754394e-03\n",
       "acousticness               -9.272985e-03\n",
       "valence                    -3.999197e-02\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "energy                      6.229851e-02\n",
       "acousticness                2.104971e-02\n",
       "speechiness                 3.564658e-03\n",
       "mean_pitch                  1.512961e-03\n",
       "mode                        1.543446e-04\n",
       "no_sections                 1.172144e-04\n",
       "sec_loudness_range          4.420773e-05\n",
       "no_unique_timbres           6.654768e-06\n",
       "key                         6.122205e-06\n",
       "duration_ms                 4.009360e-09\n",
       "tempo                      -1.684931e-06\n",
       "no_segments                -2.220996e-06\n",
       "sec_tempo_range            -7.130240e-06\n",
       "seg_duration_range         -7.910544e-06\n",
       "sec_duration_range         -7.910544e-06\n",
       "no_unique_pitches          -9.953703e-06\n",
       "sec_key_range              -2.797103e-05\n",
       "sec_time_signature_range   -1.550529e-04\n",
       "time_signature             -1.804424e-04\n",
       "sec_mode_range             -2.337952e-04\n",
       "loudness                   -5.939729e-04\n",
       "instrumentalness           -3.320682e-03\n",
       "valence                    -4.116571e-03\n",
       "liveness                   -6.341153e-03\n",
       "danceability               -1.259202e-02\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "speechiness                 2.322171e-02\n",
       "acousticness                6.197924e-04\n",
       "valence                     5.538653e-04\n",
       "mean_pitch                  4.096266e-04\n",
       "instrumentalness            1.648249e-04\n",
       "sec_mode_range              8.032378e-05\n",
       "loudness                    2.493458e-05\n",
       "mode                        2.493230e-05\n",
       "sec_key_range               6.090243e-06\n",
       "key                         5.776315e-06\n",
       "no_sections                 3.838144e-06\n",
       "sec_loudness_range          8.071445e-07\n",
       "no_unique_pitches           2.885324e-07\n",
       "no_segments                 7.130369e-08\n",
       "duration_ms                -2.592191e-10\n",
       "sec_duration_range         -2.669411e-07\n",
       "seg_duration_range         -2.669411e-07\n",
       "tempo                      -5.785456e-07\n",
       "sec_tempo_range            -1.087915e-06\n",
       "no_unique_timbres          -2.216955e-06\n",
       "time_signature             -9.053262e-06\n",
       "sec_time_signature_range   -2.203666e-05\n",
       "liveness                   -5.323579e-04\n",
       "danceability               -1.125601e-03\n",
       "energy                     -1.784013e-03\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mean_pitch                  5.800336e-03\n",
       "valence                     1.185840e-06\n",
       "loudness                    1.148197e-06\n",
       "sec_key_range               3.871027e-07\n",
       "sec_loudness_range          9.423490e-08\n",
       "no_unique_timbres           7.829334e-08\n",
       "tempo                       7.444898e-08\n",
       "sec_duration_range          5.408021e-08\n",
       "seg_duration_range          5.408021e-08\n",
       "no_segments                 2.027739e-08\n",
       "duration_ms                -6.132529e-11\n",
       "sec_tempo_range            -2.242128e-08\n",
       "key                        -1.616178e-07\n",
       "no_sections                -2.527770e-07\n",
       "sec_time_signature_range   -3.744099e-07\n",
       "mode                       -1.326301e-06\n",
       "no_unique_pitches          -1.916375e-06\n",
       "time_signature             -1.967539e-06\n",
       "instrumentalness           -7.836334e-06\n",
       "sec_mode_range             -1.014174e-05\n",
       "liveness                   -1.386852e-05\n",
       "danceability               -1.625022e-05\n",
       "acousticness               -2.461501e-05\n",
       "speechiness                -1.127804e-04\n",
       "energy                     -1.311605e-04\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sec_duration_range          3.433348e-15\n",
       "danceability                8.678086e-29\n",
       "energy                      4.015899e-29\n",
       "acousticness                3.502664e-29\n",
       "liveness                    1.595435e-29\n",
       "valence                     4.661480e-30\n",
       "mode                        2.486861e-30\n",
       "no_sections                 2.475392e-30\n",
       "sec_mode_range              2.298819e-30\n",
       "time_signature              8.932710e-31\n",
       "sec_tempo_range             3.999945e-31\n",
       "loudness                    1.626070e-31\n",
       "sec_time_signature_range    1.525107e-31\n",
       "no_unique_pitches           1.666482e-32\n",
       "duration_ms                 5.496900e-35\n",
       "no_unique_timbres          -1.535098e-32\n",
       "no_segments                -2.467096e-32\n",
       "tempo                      -7.110819e-32\n",
       "sec_loudness_range         -4.613384e-31\n",
       "key                        -6.695363e-31\n",
       "sec_key_range              -7.271947e-31\n",
       "instrumentalness           -6.497127e-30\n",
       "mean_pitch                 -6.356120e-29\n",
       "speechiness                -1.299368e-28\n",
       "seg_duration_range         -3.433348e-15\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eig_values = pca.explained_variance_\n",
    "eig_vectors = pca.components_\n",
    "\n",
    "loading_scores = [eig_vectors[i] * np.sqrt(eig_values[i]) for i in range(len(pca.components_))]\n",
    "for score in loading_scores:\n",
    "    display(pd.Series(score, index=X.columns).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.999% of variance is explained by the first component! When we look at the loading score, it looks like that direction is dominated by the duration, then to a (much) lesser extent by the number of segments, unique pitches, and unique timbres. This mostly just means that a lot of the data 'moves' in the same direction -- it's measured in ways that are highly interrelated, which makes sense for music. For example, sadder songs (closer to 0) tend to have slower tempos (closer to 0), right? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False, False,  True,  True,  True])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# need to use scaled data for SVMs\n",
    "# have random state for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "reg = SelectFromModel(LogisticRegression(C=1, penalty='l2'))\n",
    "reg.fit(X_train, y_train)\n",
    "reg.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valence',\n",
       " 'acousticness',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mean_pitch',\n",
       " 'mode',\n",
       " 'no_sections']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected = X_train.columns[(reg.get_support() == 1).ravel().tolist()]\n",
    "list(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = X[['valence',\n",
    "                 'acousticness',\n",
    "                 'key',\n",
    "                 'loudness',\n",
    "                 'mean_pitch',\n",
    "                 'mode',\n",
    "                 'no_sections']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models based on regularization\n",
    "Now that we have the features that are theoretically the most important -- let's look at them in the models that have been most successful: Random Forest and SVM. The tuned parameters from before cannot be used anymore, so if this goes well, we'll have to parameter tune again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       215\n",
      "           1       0.81      0.77      0.79       210\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       425\n",
      "   macro avg       0.80      0.80      0.80       425\n",
      "weighted avg       0.80      0.80      0.80       425\n",
      "\n",
      "ROC AUC: 0.7973421926910298\n",
      "Accuracy score: 0.7976470588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad -- now we need to tune this to see how much better it can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4500 out of 4500 | elapsed: 24.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       215\n",
      "           1       0.82      0.81      0.82       210\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       425\n",
      "   macro avg       0.82      0.82      0.82       425\n",
      "weighted avg       0.82      0.82      0.82       425\n",
      "\n",
      "ROC AUC: 0.8187153931339978\n",
      "Accuracy score: 0.8188235294117647\n",
      "None\n",
      "{'max_depth': 10, 'max_features': 8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'max_depth': [1, 5, 10],\n",
    "            'max_features': [1, 2, 4, 8],\n",
    "            'min_samples_leaf': [2, 10, 100, 500, 1000],\n",
    "            'min_samples_split': [2, 10, 100, 500, 1000],\n",
    "            'n_estimators': [100, 500, 1000]\n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       258\n",
      "           1       0.81      0.77      0.79       273\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       531\n",
      "   macro avg       0.79      0.79      0.79       531\n",
      "weighted avg       0.79      0.79      0.79       531\n",
      "\n",
      "ROC AUC: 0.7914856461368089\n",
      "Accuracy score: 0.7909604519774012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_selected, y)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter C for estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 514, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/Users/hannah/anaconda3/lib/python3.7/site-packages/sklearn/base.py\", line 215, in set_params\n    (key, self))\nValueError: Invalid parameter C for estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-2ebc67c95f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit on data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mbest_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter C for estimator RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# using non-scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create param grid.\n",
    "param_grid = {'C':[.1, 1,10,100],\n",
    "              'gamma':[1,0.1,0.001,0.0001], \n",
    "              'kernel':['linear','rbf'] \n",
    "             }\n",
    "\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv = 5, verbose=True, \n",
    "                   n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print(evaluation(y_test, y_pred))\n",
    "print(clf.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
